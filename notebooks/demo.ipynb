{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A tour of the ComPert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some standard packages to assist this tutorial\n",
    "from pprint import pprint\n",
    "import compert as cpa\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from compert.train import train_compert\n",
    "# from compert.data import load_dataset_splits\n",
    "# from compert.plotting import CompertVisuals\n",
    "# from compert.api import ComPertAPI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT. Currenlty because of the standartized evaluation procedure, we need to provide adata.obs['control'] (0 if not control, 1 for cells to use as control). And we also need to provide de_genes in .uns['rank_genes_groups']. This genes corresond to the groups of drugs in adata.obs['drug_dose_name']. adata.obs['drug_dose_name'] is a neccessary field to standartized evaluation even for the datasets that don't have doses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/anna/cpa_binaries/datasets/GSM_new.h5ad'\n",
    "compert_api = cpa.api.ComPertAPI(\n",
    "    dataset_path, \n",
    "    pretrained=None,\n",
    "    perturbation_key='condition',\n",
    "    split_key='split',\n",
    "    covariate_keys=['cell_type'],\n",
    "#     pretrained='/home/anna/cpa_binaries/pretrained_models/GSM/sweep_GSM_new_logsigm_model_seed=60_epoch=1120.pt',\n",
    "    hparams={},\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rec: -0.7740, AdvPert: 0.67, AdvCov: 0.00:   0%|          | 0/1 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model_saved\": \"./model.pt\"}\n",
      "{'ellapsed_minutes': 0.07614408334096273,\n",
      " 'epoch': 0,\n",
      " 'evaluation_stats': {'covariate disentanglement': [0.0],\n",
      "                      'ood': [0.7870016772472433,\n",
      "                              0.29051685915402303,\n",
      "                              -0.38455639914283113,\n",
      "                              -14.998942293197016],\n",
      "                      'optimal for covariates': [1.0],\n",
      "                      'optimal for perturbations': 0.2,\n",
      "                      'perturbation disentanglement': 0.7174778255356932,\n",
      "                      'test': [0.8104991585013892,\n",
      "                               0.412436435788468,\n",
      "                               -0.6482918258551059,\n",
      "                               -15.159100742885807],\n",
      "                      'training': [0.8180323798801574,\n",
      "                                   0.4184610634785806,\n",
      "                                   -0.5210729513080057,\n",
      "                                   -14.02289937656397]},\n",
      " 'training_stats': defaultdict(<class 'float'>,\n",
      "                               {'loss_adv_cell_types': 0.0,\n",
      "                                'loss_adv_covariates': 0.0,\n",
      "                                'loss_adv_drugs': 0.6701465480857425,\n",
      "                                'loss_reconstruction': -0.7740362716528276,\n",
      "                                'penalty_adv_covariates': 0.0005322548883365622,\n",
      "                                'penalty_adv_drugs': 0.003559265712586542})}\n",
      "{\"Stop epoch\": 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rec: -0.7740, AdvPert: 0.67, AdvCov: 0.00:   0%|          | 0/1 [00:47<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model_saved\": \"./model.pt\"}\n"
     ]
    }
   ],
   "source": [
    "compert_api.train(max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from compert.plotting import ComPertHistory\n",
    "# pretty_history = ComPertHistory(compert_api.model.history)\n",
    "# pretty_history.print_time()\n",
    "# pretty_history.plot_losses()\n",
    "# pretty_history.plot_metrics(epoch_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from compert.train import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ComPert API for compatibility with scanpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print and plot drug embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 5 × 256\n",
       "    obs: 'condition'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perts_anndata = compert_api.get_drug_embeddings()\n",
    "perts_anndata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print and plot covars embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 1 × 256\n",
       "    obs: 'cell_type'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covars_anndata = compert_api.get_covars_embeddings('cell_type')\n",
    "covars_anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A549_BMS_0.001': 442,\n",
       " 'A549_BMS_0.005': 391,\n",
       " 'A549_BMS_0.01': 262,\n",
       " 'A549_BMS_0.05': 134,\n",
       " 'A549_BMS_0.1': 103,\n",
       " 'A549_BMS_1.0': 13,\n",
       " 'A549_Dex_0.001': 204,\n",
       " 'A549_Dex_0.005': 264,\n",
       " 'A549_Dex_0.01': 479,\n",
       " 'A549_Dex_0.05': 484,\n",
       " 'A549_Dex_0.1': 486,\n",
       " 'A549_Dex_1.0': 568,\n",
       " 'A549_Nutlin_0.001': 284,\n",
       " 'A549_Nutlin_0.005': 252,\n",
       " 'A549_Nutlin_0.01': 387,\n",
       " 'A549_Nutlin_0.05': 350,\n",
       " 'A549_Nutlin_0.1': 457,\n",
       " 'A549_Nutlin_1.0': 6,\n",
       " 'A549_SAHA_0.001': 392,\n",
       " 'A549_SAHA_0.005': 376,\n",
       " 'A549_SAHA_0.01': 383,\n",
       " 'A549_SAHA_0.05': 299,\n",
       " 'A549_SAHA_0.1': 297,\n",
       " 'A549_SAHA_1.0': 282,\n",
       " 'A549_Vehicle_1.0': 1535}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compert_api.num_measured_points['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_comb_emb() missing 1 required positional argument: 'cov'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e24aec64f8f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompert_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_comb_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthrh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m compert_api.compute_uncertainty(\n\u001b[1;32m      3\u001b[0m                     \u001b[0mcov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'A549'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mpert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Nutlin'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mdose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1.0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_comb_emb() missing 1 required positional argument: 'cov'"
     ]
    }
   ],
   "source": [
    "compert_api.compute_comb_emb(thrh=0)\n",
    "compert_api.compute_uncertainty(\n",
    "                    cov='A549', \n",
    "                    pert='Nutlin', \n",
    "                    dose='1.0'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compert_api.measured_points['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compert_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a variable for automatic plotting. The plots also could be used separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compert_plots = CompertVisuals(compert_api, fileprefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compert_plots.plot_latent_embeddings(compert_api.emb_perts, kind='perturbations', show_text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your have a lot of cell types or a lot of perturbations, you can also chose to not display their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compert_plots.plot_latent_embeddings(compert_api.emb_perts, kind='perturbations', show_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or I can change the color scheme for the emebddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perts_palette = {'BMS': '#999999',                 \n",
    "                 'SAHA': '#4daf4a',\n",
    "                 'Dex': '#377eb8',\n",
    "                 'Nutlin': '#e41a1c',\n",
    "                 'Vehicle': '#000000'\n",
    "    \n",
    "                }\n",
    "\n",
    "compert_plots.perts_palette = perts_palette\n",
    "compert_plots.plot_latent_embeddings(compert_api.emb_perts, kind='perturbations', show_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compert_plots.plot_latent_embeddings(compert_api.emb_covars, kind='covars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_response = compert_api.latent_dose_response(perturbations=None)\n",
    "compert_plots.plot_contvar_response(\n",
    "    latent_response, \n",
    "    postfix='latent',\n",
    "    var_name=compert_api.perturbation_key,\n",
    "    title_name='Latent dose response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbations_pair = ['Nutlin', 'BMS']\n",
    "latent_dose_2D = compert_api.latent_dose_response2D(perturbations_pair, n_points=100)\n",
    "compert_plots.plot_contvar_response2D(latent_dose_2D, \n",
    "        title_name='Latent dose-response')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "reconstructed_response2D = compert_api.get_response2D(datasets, perturbations_pair, compert_api.unique_сovars[0])\n",
    "compert_plots.plot_contvar_response2D(reconstructed_response2D,\n",
    "                                              title_name='Reconstructed dose-response  2D',\n",
    "                                              logdose=False,\n",
    "                                              # xlims=(-3, 0), ylims=(-3, 0)\n",
    "                                              )\n",
    "\n",
    "compert_plots.plot_contvar_response2D(reconstructed_response2D,\n",
    "                                      title_name='Reconstructed log10-dose-response 2D',\n",
    "                                      logdose=True,\n",
    "                                      xlims=(-3, 0), ylims=(-3, 0)\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to plot in on a log scale, you can just log values in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "df_reference = compert_api.get_response_reference(datasets)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "reconstructed_response = compert_api.get_response(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot an average response (saved under \"response\" column) among all genes, however, we don't consider it to be a good metric and strongly advise to look at the individual response among DE genes.\n",
    "\n",
    "Solid lines in this plot correspond to the model predictions, dashed lines -- linear interpolations between measured points. Dots represent measured points, their color is proportional to the number of cells in this condition. Black dots represent points used in training and red dots correspond to the out-of-distribution examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reference = df_reference.replace('training_treated', 'train')\n",
    "compert_plots.plot_contvar_response(\n",
    "    reconstructed_response, \n",
    "    df_ref=df_reference, \n",
    "    postfix='reconstructed',\n",
    "    title_name='Reconstructed dose response')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example we can take of the top 50 DE genes for Nutlin - MDM2. MDM2 is itself transcriptionally-regulated by p53. And p53 is the target of Nutlin. Therefore, we expect our model to learn it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compert_plots.plot_contvar_response(\n",
    "    reconstructed_response, \n",
    "    df_ref=df_reference,\n",
    "    response_name='MDM2',\n",
    "    postfix='MDM2',\n",
    "    title_name='Reconstructed dose response of MDM2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at this plot on the log10-scale. It makes sense for this dataset, because the measured doses were not evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compert_plots.plot_contvar_response(\n",
    "    reconstructed_response, \n",
    "    df_ref=df_reference,\n",
    "    response_name='MDM2',\n",
    "    postfix='MDM2',\n",
    "    logdose=True,\n",
    "    title_name='Reconstructed log10-dose response of MDM2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Perturbations:', compert_api.unique_perts)\n",
    "print('Covariates:', compert_api.unique_сovars)\n",
    "print('Datasets splits:', datasets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can chose control cells from which we want to make our predictions. It is easy to chose these cells from either training or test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_control = datasets['test_control'].genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({args['perturbation_key']: ['BMS', 'Dex'], \n",
    "                   args['dose_key']: ['1.0', '0.5'], \n",
    "                   args['cell_type_key']: ['A549', 'A549']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the prediction function returns means and variances of the applied perturbations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "compert_api.predict(genes_control, df, return_anndata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the prediction function returns means and variances of the applied perturbations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anndata_predicted = compert_api.predict(genes_control, df, return_anndata=True, sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in some cases you want to sample from this distribution, so you can explicitly specify it in the predict function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anndata_predicted_samples = compert_api.predict(genes_control, df, return_anndata=True, sample=True, n_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_control = datasets['training_control'].genes\n",
    "df_train = compert_api.evaluate_r2(datasets['training_treated'], genes_control)\n",
    "df_train['benchmark'] = 'CPA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_control = datasets['test_control'].genes\n",
    "df_ood = compert_api.evaluate_r2(datasets['ood'], genes_control)\n",
    "df_ood['benchmark'] = 'CPA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_control = datasets['test_control'].genes\n",
    "df_test = compert_api.evaluate_r2(datasets['test_treated'], genes_control)\n",
    "df_test['benchmark'] = 'CPA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = compert_api.evaluate_r2(datasets['test_treated'], genes_control)\n",
    "df_test['benchmark'] = 'CPA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ood['split'] = 'ood'\n",
    "df_test['split'] ='test'\n",
    "df_train['split'] ='train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_score = pd.concat([df_train, df_test, df_ood])\n",
    "df_score.round(2).sort_values(by=['condition', 'R2_mean', 'R2_mean_DE'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_print = ['condition', 'dose_val','R2_mean', 'R2_mean_DE', 'R2_var', 'R2_var_DE', 'split', 'num_cells']\n",
    "df_score = df_score.round(2).sort_values(by=['condition', 'R2_mean', 'R2_mean_DE'], ascending=False)\n",
    "print(df_score[cols_print])\n",
    "# print(df_score[cols_print].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can profile all the predictions with an uncertainty score. Low uncertainty means \"good/trustworthy\" predictions, high values mean \"bad/unknown quality\" predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compert.plotting as pl\n",
    "\n",
    "for drug in ['Nutlin', 'BMS', 'Dex', 'SAHA']:\n",
    "    df_pred = pl.plot_uncertainty_dose(\n",
    "        compert_api,\n",
    "        cov='A549',\n",
    "        pert=drug,\n",
    "        N=51,\n",
    "        measured_points=compert_api.measured_points['all'],\n",
    "        cond_key='condition',\n",
    "        log=True,\n",
    "        metric='cosine'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we demonstrated CPA predictions for drugs combinations. But our training data didn't contain any combinations examples. How much can we trust these examples? We can try to asses by running model uncertainty predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred2D = pl.plot_uncertainty_comb_dose(\n",
    "    compert_api=compert_api,\n",
    "    cov='A549',\n",
    "    pert='Nutlin+BMS',\n",
    "    N=51,\n",
    "    cond_key='treatment',\n",
    "    metric='cosine',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the predicted response we plotted before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compert_plots.plot_contvar_response2D(reconstructed_response2D, \n",
    "    title_name='Reconstructed dose-response', logdose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now keep in mind, that the highest uncertainty for OOD cases (for which we know that their predictions were fairly good) is 0.002:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['uncertainty_cosine'].max().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, be careful with interpreting drug combinations in this dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compert_api.measured_points['training']['A549']['Nutlin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
